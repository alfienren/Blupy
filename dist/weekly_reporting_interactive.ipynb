{
 "metadata": {
  "name": "",
  "signature": "sha256:360624f1d77a92cfaa91c7104ea0ef827dfc9cc2caeb8830bb3e14a96968d41f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from xlwings import Workbook, Range, Sheet\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chunk_df(df, sheet, startcell, chunk_size = 1000):\n",
      "    if len(df) <= (chunk_size + 1):\n",
      "        Range(sheet, startcell, index = False, header = True).value = df\n",
      "    else:\n",
      "        c = re.match(r\"([a-z]+)([0-9]+)\", startcell, re.I)\n",
      "        row = c.group(1)\n",
      "        col = int(c.group(2))\n",
      "        \n",
      "        for chunk in (df[rw:rw + chunk_size] for rw in \n",
      "                      range(0, len(df), chunk_size)):\n",
      "            Range(sheet, row + str(col), index = False, header = False).value = chunk\n",
      "            col += chunk_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wb = Workbook('')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sa = pd.DataFrame(pd.read_excel(wb, 'SA_Temp', index_col = None))\n",
      "#cfv = pd.DataFrame(pd.read_excel(wb, 'CFV_Temp', index_col = None))\n",
      "    \n",
      "sa = pd.DataFrame(Range('SA_Temp', 'A1').table.value, columns = Range('SA_Temp', 'A1').horizontal.value)\n",
      "cfv = pd.DataFrame(Range('CFV_Temp', 'A1').table.value, columns = Range('CFV_Temp', 'A1').horizontal.value)\n",
      "    \n",
      "sa.drop(0, inplace = True)    \n",
      "cfv.drop(0, inplace = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfv['Orders'] = 1\n",
      "cfv['Plans'] = cfv['Plan (string)'].str.count(',') + 1\n",
      "cfv['Devices'] = cfv['Device (string)'].str.count(',') + 1\n",
      "cfv['Services'] = cfv['Service (string)'].str.count(',') + 1\n",
      "cfv['Add-a-Line'] = cfv['Service (string)'].str.count('ADD')\n",
      "cfv['Accessories'] = cfv['Accessory (string)'].str.count(',') + 1\n",
      "cfv['Activations'] = cfv['Plans'] + cfv['Add-a-Line']\n",
      "    \n",
      "cfv['Postpaid Plans'] = np.where(cfv['Plans'] == cfv['Devices'], cfv['Plans'], pd.concat([cfv['Plans'], cfv['Devices']], axis=1).min(axis=1))\n",
      "cfv['Prepaid Plans'] = np.where((cfv['Plans'] == 0) & (cfv['Devices'] != 0), 0, cfv['Devices'])\n",
      "    \n",
      "cfv ['Orders'] = np.where((cfv['Campaign'].str.contains('DDR') == True) & (cfv['Floodlight Attribution Type'].str.contains('View-through') == True),\n",
      "                            cfv['Orders'] * 0.5, cfv['Orders'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = sa.append(cfv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['Media Cost'] = np.where(data['DBM Cost USD'] != 0, data['DBM Cost USD'], data['Media Cost'])\n",
      "data.drop('DBM Cost USD', 1, inplace = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['Click-through URL'] = data['Click-through URL'].str.replace('http://analytics.bluekai.com/site/', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3F%3DADV_DS_%epid!_%eaid!_%ecid!_%eadv!', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('15991\\?phint', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('http://15991\\?phint', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('event%3Dclick&phint', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('aid%3D%eadv!&phint', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('pid%3D%epid!&phint', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('cid%3D%ebuy!&phint', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('crid%3D%ecid!&done', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('pid%3D%25epid!&phint', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3D%epid!_%eaid!_%ecid!_%eadv!', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%26csdids', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('DADV_DS_ADDDVL4Q_EMUL7Y9E1YA4116', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('DWTR_DD_DDRDSPLYPR_JM2694TSP3U5895', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('DWTR_DD_DDRFCBK_RQLMKXRCUQZ1042', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3Fcmpid%3', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('b/refmh_', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3Fcm_mmc%3DPurchase-_-Display-_-Revere-_-Revere', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3Fcm_mmc%3DDisplay-_-Purchase-_-GM-_-Tablet_Base', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3Fcmpid%3DWTR_DD_DDRFCBK_RQLMKXRCUQZ1042%26csdids%3D%epid!_%eaid!_%ecid!_%eadv!', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3F%26csdids%3DADV_DS_%epid!_%eaid!_%ecid!_%eadv!', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3Fcm_mmc%3DPurchase-_-Display-_-Revere-_-Revere%26csdids%3D%epid!_%eaid!_%ecid!_%eadv!', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3Fcm_mmc%3DDisplay-_-Purchase-_-GM-_-Tablet_Base%26csdids%3D%epid!_%eaid!_%ecid!_%eadv!', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3Fcmpid%3DWTR_DD_DDRDSPLYPR_JM2694TSP3U5895%26csdids%3D%epid!_%eaid!_%ecid!_%eadv!', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('&csdids%epid!_%eaid!_%ecid!_%eadv!', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('=', '')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%2F', '/')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%3A', ':')\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('%23', '#')\n",
      "data['Click-through URL'] = data['Click-through URL'].apply(lambda x: str(x).split('.html')[0])\n",
      "data['Click-through URL'] = data['Click-through URL'].apply(lambda x: str(x).split('?')[0])\n",
      "data['Click-through URL'] = data['Click-through URL'].apply(lambda x: str(x).split('%')[0])\n",
      "data['Click-through URL'] = data['Click-through URL'].apply(lambda x: str(x).split('_')[0])\n",
      "data['Click-through URL'] = data['Click-through URL'].str.replace('DWTR', '') "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['Plans'].fillna(0, inplace = True)\n",
      "data['Services'].fillna(0, inplace = True)\n",
      "data['Devices'].fillna(0, inplace = True)\n",
      "data['Accessories'].fillna(0, inplace = True)\n",
      "data['Orders'].fillna(0, inplace = True)\n",
      "    \n",
      "data['Plan (string)'] = np.where(data['Plans'] < 1, '', data['Plan (string)'])\n",
      "    \n",
      "data['Service (string)'] = np.where(data['Services'] < 1, '', data['Service (string)'])\n",
      "    \n",
      "data['Accessory (string)'] = np.where(data['Accessories'] < 1, '', data['Accessory (string)'])\n",
      "    \n",
      "data['Device (string)'] = np.where(data['Devices'] < 1, \"\", data['Device (string)'])\n",
      "    \n",
      "data['OrderNumber (string)'] = np.where(data['Orders'] < 1, '', data['OrderNumber (string)'])\n",
      "    \n",
      "data['Activity'] = np.where(data['Orders'] < 1, '', data['Activity'])\n",
      "    \n",
      "data['Floodlight Attribution Type'] = np.where(data['Orders'] < 1, '', data['Floodlight Attribution Type'])\n",
      "    \n",
      "data['Devices'] = np.where(data['Device (string)'].str.contains('nan') == True, 0, data['Devices'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_actions = Range('Action_Reference', 'A2').vertical.value\n",
      "b_actions = Range('Action_Reference', 'B2').vertical.value\n",
      "c_actions = Range('Action_Reference', 'C2').vertical.value\n",
      "d_actions = Range('Action_Reference', 'D2').vertical.value\n",
      "e_actions = Range('Action_Reference', 'E2').vertical.value\n",
      "    \n",
      "column_names = data.columns\n",
      "    \n",
      "a_actions = list(set(a_actions).intersection(column_names))\n",
      "b_actions = list(set(b_actions).intersection(column_names))\n",
      "c_actions = list(set(c_actions).intersection(column_names))\n",
      "d_actions = list(set(d_actions).intersection(column_names))\n",
      "e_actions = list(set(e_actions).intersection(column_names))\n",
      "    \n",
      "data['A Actions'] = data[a_actions].sum(axis=1)\n",
      "data['B Actions'] = data[b_actions].sum(axis=1)\n",
      "data['C Actions'] = data[c_actions].sum(axis=1)\n",
      "data['D Actions'] = data[d_actions].sum(axis=1)\n",
      "data['E Actions'] = data[e_actions].sum(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mobile = '|'.join(list(Range('Lookup', 'B2:B6').value))\n",
      "tablet = '|'.join(list(Range('Lookup', 'B7:B9').value))\n",
      "social = '|'.join(list(Range('Lookup', 'B10:B12').value))\n",
      "    \n",
      "rm = '|'.join(list(Range('Lookup', 'D2:D5').value))\n",
      "custom = '|'.join(list(Range('Lookup', 'D6:D15').value))\n",
      "rem = '|'.join(list(Range('Lookup', 'D16:D28').value))\n",
      "    \n",
      "dynamic = '|'.join(list(Range('Lookup', 'F2:F3').value))\n",
      "other_buy = '|'.join(list(Range('Lookup', 'F4').value))\n",
      "    \n",
      "platform = np.where(data['Placement'].str.contains(mobile) == True, 'Mobile',\n",
      "                    np.where(data['Placement'].str.contains(tablet) == True, 'Tablet',\n",
      "                             np.where(data['Placement'].str.contains(social) == True, 'Social', '')))\n",
      "    \n",
      "creative = np.where(data['Placement'].str.contains(rm) == True, 'Rich Media',\n",
      "                    np.where(data['Placement'].str.contains(custom) == True, 'Custom',\n",
      "                             np.where(data['Placement'].str.contains(rem) == True, 'Remessaging', 'Standard')))\n",
      "    \n",
      "buy = np.where(data['Placement'].str.contains(dynamic) == True, 'dCPM',\n",
      "                np.where(data['Placement'].str.contains(other_buy), 'Flat', ''))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "view_through = []\n",
      "for i in column_names:\n",
      "    view = re.search('View-through Conversions', i)\n",
      "    if view:\n",
      "        view_through.append(i)\n",
      "    \n",
      "click_through = []\n",
      "for i in column_names:\n",
      "    click = re.search('Click-through Conversions', i)\n",
      "    if click:\n",
      "        click_through.append(i)\n",
      "    \n",
      "store_locator = []\n",
      "for i in column_names:\n",
      "    locator = re.search('Store Locator', i)\n",
      "    if locator:\n",
      "        store_locator.append(i)\n",
      "    \n",
      "view_based = list(set(view_through).intersection(column_names))\n",
      "click_based = list(set(click_through).intersection(column_names))\n",
      "SLV_conversions = list(set(store_locator).intersection(column_names))\n",
      "    \n",
      "data['Post-Click Activity'] = data[click_based].sum(axis=1)\n",
      "data['Post-Impression Activity'] = data[view_based].sum(axis=1)\n",
      "data['Store Locator Visits'] = data[SLV_conversions].sum(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['Awareness Actions'] = data['A Actions'] + data['B Actions']\n",
      "data['Consideration Actions'] = data['C Actions'] + data['D Actions']\n",
      "data['Traffic Actions'] = data['Awareness Actions'] + data['Consideration Actions']\n",
      "\n",
      "data['eGAs'] = np.where(data['Floodlight Attribution Type'].str.contains('View-through') == True,\n",
      "                        (data['Device (string)'].str.count(',') + 1) / 2, \n",
      "                            data['Device (string)'].str.count(',') + 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['Creative Field 1'] = data['Creative Field 1'].str.replace('Creative Type: ', '')\n",
      "data['Creative Field 1'] = data['Creative Field 1'].str.replace('(', '')\n",
      "data['Creative Field 1'] = data['Creative Field 1'].str.replace(')', '')\n",
      "data['Creative Field 1'] = data['Creative Field 1'].str.replace('not set', 'TMO Unique Creative')\n",
      "    \n",
      "data['Message Bucket'] = data['Creative Field 1'].str.split('_').str.get(0)\n",
      "    \n",
      "data['Message Category'] = data['Creative Field 1'].str.split('_').str.get(1)\n",
      "    \n",
      "data['Message Offer'] = data['Creative Field 1'].str.split('_').str.get(2)\n",
      "data['Message Offer'].fillna(data['Creative Groups 2'], inplace=True)\n",
      "\n",
      "data['Platform'] = platform\n",
      "data['P_Creative'] = creative\n",
      "data['Buy'] = buy\n",
      "    \n",
      "data['Category'] = data['Platform'] + ' - ' + data['P_Creative'] + ' - ' + data['Buy']\n",
      "    \n",
      "data['Category'] = np.where(data['Category'].str[:3] == ' - ', data['Category'].str[3:], data['Category'])\n",
      "data['Category'] = np.where(data['Category'].str[-3:] == ' - ', data['Category'].str[:-3], data['Category'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['Week'] = data['Date'].min()\n",
      "data['Video Completions'] = 0\n",
      "data['Video Views'] = 0\n",
      "    \n",
      "data['F Tag'] = 0\n",
      "data['F Actions'] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sa_columns = list(sa.columns)\n",
      "    \n",
      "dimensions = ['Week', 'Date', 'Campaign', 'Site (DCM)', 'Click-through URL', 'F Tag', 'Category', 'Message Bucket', 'Message Category', \n",
      "                'Message Offer', 'Creative', 'Ad', 'Creative Groups 1', 'Creative Groups 2', 'Creative ID', 'Creative Type', \n",
      "                'Creative Field 1', 'Placement', 'Placement Cost Structure', 'OrderNumber (string)', 'Activity', 'Floodlight Attribution Type',\n",
      "                'Plan (string)', 'Device (string)', 'Service (string)', 'Accessory (string)']\n",
      "    \n",
      "metrics = ['Media Cost', 'Impressions', 'Clicks', 'Orders', 'Plans', 'Add-a-Line', 'Activations', 'Devices', 'Services', 'Accessories',\n",
      "            'Prepaid Plans', 'eGAs', 'Store Locator Visits', 'A Actions', 'B Actions', 'C Actions', 'D Actions', 'E Actions', 'F Actions', \n",
      "            'Awareness Actions', 'Consideration Actions', 'Traffic Actions', 'Post-Click Activity', 'Post-Impression Activity',\n",
      "            'Video Completions', 'Video Views']\n",
      "\n",
      "action_tags = sa_columns[sa_columns.index('DBM Cost USD') + 1:]\n",
      "    \n",
      "new_columns = dimensions + metrics + action_tags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = data[new_columns]\n",
      "chunk_df(data, 'working', 'A1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_tag_range = Range('working', 'F2').vertical\n",
      "    \n",
      "for cell in f_tag_range:\n",
      "    url = cell.offset(0, -1).get_address(False, False, False)\n",
      "    cell.formula = '=IF(' + url + '=\"http://www.t-mobile.com/\",\"na\",IFERROR(INDEX(F_Tags!C:C,MATCH(working!' + url + ',F_Tags!E:E,0)),\"na\"))'\n",
      "        \n",
      "data['F Tag'] = Range('working', 'F2').vertical.value\n",
      "    \n",
      "f_tags = []\n",
      "for i in data['F Tag']:\n",
      "    for j in data.columns:\n",
      "        tag = re.search(i, j)\n",
      "        if tag:\n",
      "            f_tags.append(j)\n",
      "    \n",
      "f_tags = list(set(f_tags).intersection(data.columns))\n",
      "f_conversions = list(set(f_tags).intersection(data.columns))\n",
      "    \n",
      "data['F Actions'] = data[f_conversions].sum(axis=1)\n",
      "    \n",
      "data['F Tag'] = data['F Tag'].apply(lambda x: str(x).split(':')[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_columns = dimensions + metrics + action_tags\n",
      "\n",
      "data = data[data_columns]\n",
      "data.fillna(0, inplace = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wb.save()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "past_data = pd.DataFrame(Range('data', 'A1').table.value, columns = Range('data', 'A1').horizontal.value)\n",
      "past_data.drop(0, inplace = True)\n",
      "appended_data = past_data.append(data)\n",
      "appended_data = appended_data[data_columns]\n",
      "appended_data.drop_duplicates(inplace = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Sheet('data').clear_contents()\n",
      "    \n",
      "Range('data', 'A1').value = list(appended_data.columns)\n",
      "chunk_df(appended_data, 'data', 'A2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}